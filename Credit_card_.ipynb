{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6hieFRZDrC9CoC/+Nq29M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnwarMohamedhyphen/datascience-notebooks/blob/main/Credit_card_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Credit Card Fraud Detection (CRISP-DM) - Google Colab Version\\n\",\n",
        "    \"---\\n\",\n",
        "    \"This notebook is fully formatted for Google Colab with separate cells for each CRISP-DM stage.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 1. Install Optional Libraries (if not installed)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"!pip install numpy pandas matplotlib scikit-learn joblib\\n\",\n",
        "    \"!pip install xgboost imbalanced-learn --quiet\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 2. Import Libraries\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"import os\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
        "    \"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\\n\",\n",
        "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
        "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
        "    \"from sklearn.pipeline import Pipeline\\n\",\n",
        "    \"import joblib\\n\",\n",
        "    \"import warnings\\n\",\n",
        "    \"warnings.filterwarnings('ignore')\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 3. Load or Generate Data\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"def load_data(csv_path='creditcard.csv', n_samples=120000):\\n\",\n",
        "    \"    if os.path.exists(csv_path):\\n\",\n",
        "    \"        print(f'Loading real dataset: {csv_path}')\\n\",\n",
        "    \"        df = pd.read_csv(csv_path)\\n\",\n",
        "    \"        return df\\n\",\n",
        "    \"    else:\\n\",\n",
        "    \"        print('No CSV found. Generating synthetic dataset...')\\n\",\n",
        "    \"        from sklearn.datasets import make_classification\\n\",\n",
        "    \"        X, y = make_classification(n_samples=n_samples, n_features=30, n_informative=15, n_redundant=5, weights=[0.995,0.005], class_sep=1.6, random_state=42)\\n\",\n",
        "    \"        cols = [f'V{i}' for i in range(1,29)] + ['Amount','Time']\\n\",\n",
        "    \"        df = pd.DataFrame(X, columns=cols)\\n\",\n",
        "    \"        df['Class'] = y.astype(int)\\n\",\n",
        "    \"        return df\\n\",\n",
        "    \"\\n\",\n",
        "    \"df = load_data()\\n\",\n",
        "    \"df.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 4. Explore Data (EDA)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"print('Dataset shape:', df.shape)\\n\",\n",
        "    \"print('Class distribution:\\n', df['Class'].value_counts(normalize=True))\\n\",\n",
        "    \"print('Missing values:\\n', df.isna().sum())\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 5. Data Preparation\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"X = df.drop('Class', axis=1)\\n\",\n",
        "    \"y = df['Class']\\n\",\n",
        "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\\n\",\n",
        "    \"scaler = StandardScaler()\\n\",\n",
        "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
        "    \"X_test_scaled = scaler.transform(X_test)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 6. Model Training\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Logistic Regression\\n\",\n",
        "    \"logreg = LogisticRegression(max_iter=2000, class_weight='balanced')\\n\",\n",
        "    \"logreg.fit(X_train_scaled, y_train)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Random Forest\\n\",\n",
        "    \"rf = RandomForestClassifier(n_estimators=400, class_weight='balanced', n_jobs=-1, random_state=42)\\n\",\n",
        "    \"rf.fit(X_train_scaled, y_train)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 7. Model Evaluation\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"def evaluate_model(model, X_test, y_test, name):\\n\",\n",
        "    \"    y_pred = model.predict(X_test)\\n\",\n",
        "    \"    y_scores = model.predict_proba(X_test)[:,1] if hasattr(model,'predict_proba') else model.decision_function(X_test)\\n\",\n",
        "    \"    print('---', name, '---')\\n\",\n",
        "    \"    print('Confusion Matrix:\\n', confusion_matrix(y_test,y_pred))\\n\",\n",
        "    \"    print('Classification Report:\\n', classification_report(y_test,y_pred,digits=4))\\n\",\n",
        "    \"    fpr, tpr, _ = roc_curve(y_test, y_scores)\\n\",\n",
        "    \"    plt.figure()\\n\",\n",
        "    \"    plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc_score(y_test,y_scores):.4f}')\\n\",\n",
        "    \"    plt.plot([0,1],[0,1],'--')\\n\",\n",
        "    \"    plt.xlabel('False Positive Rate')\\n\",\n",
        "    \"    plt.ylabel('True Positive Rate')\\n\",\n",
        "    \"    plt.title(f'ROC Curve - {name}')\\n\",\n",
        "    \"    plt.legend()\\n\",\n",
        "    \"    plt.show()\\n\",\n",
        "    \"    precision, recall, _ = precision_recall_curve(y_test,y_scores)\\n\",\n",
        "    \"    plt.figure()\\n\",\n",
        "    \"    plt.plot(recall, precision, label=f'PR AUC = {average_precision_score(y_test,y_scores):.4f}')\\n\",\n",
        "    \"    plt.xlabel('Recall')\\n\",\n",
        "    \"    plt.ylabel('Precision')\\n\",\n",
        "    \"    plt.title(f'Precision-Recall Curve - {name}')\\n\",\n",
        "    \"    plt.legend()\\n\",\n",
        "    \"    plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"evaluate_model(logreg, X_test_scaled, y_test, 'Logistic Regression')\\n\",\n",
        "    \"evaluate_model(rf, X_test_scaled, y_test, 'Random Forest')\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 8. Save Best Model\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"best_model = rf  # choose the best by PR-AUC\\n\",\n",
        "    \"joblib.dump(best_model, 'best_fraud_model.joblib')\\n\",\n",
        "    \"print('Saved best model as best_fraud_model.joblib')\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\"kernelspec\": {\"name\": \"python3\", \"display_name\": \"Python 3\"}, \"language_info\": {\"name\": \"python\"}},\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 5\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5tnDSxSMHLr",
        "outputId": "7809f610-217b-4c2c-c206-5f6c8117f457"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cells': [{'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['# Credit Card Fraud Detection (CRISP-DM) - Google Colab Version\\n',\n",
              "    '---\\n',\n",
              "    'This notebook is fully formatted for Google Colab with separate cells for each CRISP-DM stage.']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 1. Install Optional Libraries (if not installed)']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': ['!pip install numpy pandas matplotlib scikit-learn joblib\\n',\n",
              "    '!pip install xgboost imbalanced-learn --quiet']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 2. Import Libraries']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': ['import os\\n',\n",
              "    'import numpy as np\\n',\n",
              "    'import pandas as pd\\n',\n",
              "    'import matplotlib.pyplot as plt\\n',\n",
              "    'from sklearn.model_selection import train_test_split\\n',\n",
              "    'from sklearn.preprocessing import StandardScaler\\n',\n",
              "    'from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\\n',\n",
              "    'from sklearn.linear_model import LogisticRegression\\n',\n",
              "    'from sklearn.ensemble import RandomForestClassifier\\n',\n",
              "    'from sklearn.pipeline import Pipeline\\n',\n",
              "    'import joblib\\n',\n",
              "    'import warnings\\n',\n",
              "    \"warnings.filterwarnings('ignore')\"]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 3. Load or Generate Data']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': [\"def load_data(csv_path='creditcard.csv', n_samples=120000):\\n\",\n",
              "    '    if os.path.exists(csv_path):\\n',\n",
              "    \"        print(f'Loading real dataset: {csv_path}')\\n\",\n",
              "    '        df = pd.read_csv(csv_path)\\n',\n",
              "    '        return df\\n',\n",
              "    '    else:\\n',\n",
              "    \"        print('No CSV found. Generating synthetic dataset...')\\n\",\n",
              "    '        from sklearn.datasets import make_classification\\n',\n",
              "    '        X, y = make_classification(n_samples=n_samples, n_features=30, n_informative=15, n_redundant=5, weights=[0.995,0.005], class_sep=1.6, random_state=42)\\n',\n",
              "    \"        cols = [f'V{i}' for i in range(1,29)] + ['Amount','Time']\\n\",\n",
              "    '        df = pd.DataFrame(X, columns=cols)\\n',\n",
              "    \"        df['Class'] = y.astype(int)\\n\",\n",
              "    '        return df\\n',\n",
              "    '\\n',\n",
              "    'df = load_data()\\n',\n",
              "    'df.head()']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 4. Explore Data (EDA)']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': [\"print('Dataset shape:', df.shape)\\n\",\n",
              "    \"print('Class distribution:\\n', df['Class'].value_counts(normalize=True))\\n\",\n",
              "    \"print('Missing values:\\n', df.isna().sum())\"]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 5. Data Preparation']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': [\"X = df.drop('Class', axis=1)\\n\",\n",
              "    \"y = df['Class']\\n\",\n",
              "    'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\\n',\n",
              "    'scaler = StandardScaler()\\n',\n",
              "    'X_train_scaled = scaler.fit_transform(X_train)\\n',\n",
              "    'X_test_scaled = scaler.transform(X_test)']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 6. Model Training']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': ['# Logistic Regression\\n',\n",
              "    \"logreg = LogisticRegression(max_iter=2000, class_weight='balanced')\\n\",\n",
              "    'logreg.fit(X_train_scaled, y_train)\\n',\n",
              "    '\\n',\n",
              "    '# Random Forest\\n',\n",
              "    \"rf = RandomForestClassifier(n_estimators=400, class_weight='balanced', n_jobs=-1, random_state=42)\\n\",\n",
              "    'rf.fit(X_train_scaled, y_train)']},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 7. Model Evaluation']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': ['def evaluate_model(model, X_test, y_test, name):\\n',\n",
              "    '    y_pred = model.predict(X_test)\\n',\n",
              "    \"    y_scores = model.predict_proba(X_test)[:,1] if hasattr(model,'predict_proba') else model.decision_function(X_test)\\n\",\n",
              "    \"    print('---', name, '---')\\n\",\n",
              "    \"    print('Confusion Matrix:\\n', confusion_matrix(y_test,y_pred))\\n\",\n",
              "    \"    print('Classification Report:\\n', classification_report(y_test,y_pred,digits=4))\\n\",\n",
              "    '    fpr, tpr, _ = roc_curve(y_test, y_scores)\\n',\n",
              "    '    plt.figure()\\n',\n",
              "    \"    plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc_score(y_test,y_scores):.4f}')\\n\",\n",
              "    \"    plt.plot([0,1],[0,1],'--')\\n\",\n",
              "    \"    plt.xlabel('False Positive Rate')\\n\",\n",
              "    \"    plt.ylabel('True Positive Rate')\\n\",\n",
              "    \"    plt.title(f'ROC Curve - {name}')\\n\",\n",
              "    '    plt.legend()\\n',\n",
              "    '    plt.show()\\n',\n",
              "    '    precision, recall, _ = precision_recall_curve(y_test,y_scores)\\n',\n",
              "    '    plt.figure()\\n',\n",
              "    \"    plt.plot(recall, precision, label=f'PR AUC = {average_precision_score(y_test,y_scores):.4f}')\\n\",\n",
              "    \"    plt.xlabel('Recall')\\n\",\n",
              "    \"    plt.ylabel('Precision')\\n\",\n",
              "    \"    plt.title(f'Precision-Recall Curve - {name}')\\n\",\n",
              "    '    plt.legend()\\n',\n",
              "    '    plt.show()']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': [\"evaluate_model(logreg, X_test_scaled, y_test, 'Logistic Regression')\\n\",\n",
              "    \"evaluate_model(rf, X_test_scaled, y_test, 'Random Forest')\"]},\n",
              "  {'cell_type': 'markdown',\n",
              "   'metadata': {},\n",
              "   'source': ['## 8. Save Best Model']},\n",
              "  {'cell_type': 'code',\n",
              "   'metadata': {},\n",
              "   'source': ['best_model = rf  # choose the best by PR-AUC\\n',\n",
              "    \"joblib.dump(best_model, 'best_fraud_model.joblib')\\n\",\n",
              "    \"print('Saved best model as best_fraud_model.joblib')\"]}],\n",
              " 'metadata': {'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
              "  'language_info': {'name': 'python'}},\n",
              " 'nbformat': 4,\n",
              " 'nbformat_minor': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}